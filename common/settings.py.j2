# This settings file template controls the Lasair pipeline, webserver, cronjobs, 
# and command line operations.
# The template is instantiated on multiple nodes into settings.py
# and can then be modified locally.
# Note that github has this template file, but not the instantiations, 
# because those have secrets.

# Kafka operation
#################
# The internal address of the Kafka service by which pipeline components communicate
KAFKA_SERVER           = '{{ settings.kafka_producer }}:9092'

# Arbitrary Group ID for private Kafka, can be changed at will in an 
# instantiated settings.py
KAFKA_GROUPID          = 'LASAIR1'

# The server for the public kafka, where filter streams are prodced
# with its username and password
PUBLIC_KAFKA_SERVER    = 'kafka-pub:29092'
PUBLIC_KAFKA_USERNAME  = 'admin'
PUBLIC_KAFKA_PASSWORD  = '{{ settings.kafka_password }}'

# Internal address of the public kafka producer
INTERNAL_KAFKA_PRODUCER= '{{ settings.kafka_producer }}:9092'

# Group ID for public kafka, can be changed at will in an instantiated settings.py
PUBLIC_GROUP_ID        = 'test124'

# Pipeline runtime
##################
# If not present, pipeline comonents will not start a new batch
LOCKFILE               = '/home/ubuntu/lockfile'

# Alerts per batch. Can be modified in an instantiated settings.py
KAFKA_MAXALERTS        = 40000

# Time to wait beterrn batches
WAIT_TIME              = 180

# When something goes wrong
SLACK_URL              = 'https://hooks.slack.com/services/{{ settings.slack_url_urlhook }}'

# Relational database mysql/galera
##################################
DB_HOST                = '{{ db_host }}'
DB_PORT                = '{{ settings.master_db_port }}'
DB_DATABASE            = 'ztf'
DB_ROOT_PASS           = '{{ settings.master_db_root_password }}'

# Read/write access
DB_USER_READWRITE      = '{{ settings.master_db_username }}'
DB_PASS_READWRITE      = '{{ settings.master_db_password }}'

# Read only access
DB_USER_READONLY       = '{{ settings.master_db_readonly_username }}'
DB_PASS_READONLY       = '{{ settings.master_db_readonly_password }}'

# Local database on filter nodes
LOCAL_DB_HOST           = 'localhost'
LOCAL_DB_USER           = 'ztf'
LOCAL_DB_PASS           = '{{ settings.local_db_password }}'

# Cassandra NoSQL database
##########################
# Cassandra headnode
CASSANDRA_HEAD          = "{{ groups['cassandranodes'] }}"

# Table names
CASSANDRA_CANDIDATES    = 'candidates'
CASSANDRA_NONCANDIDATES = 'noncandidates'

# Directories on share Cephfs
#############################
IMAGEFITS              = '/mnt/cephfs/lasair/fits'
SYSTEM_STATUS          = '/mnt/cephfs/lasair/system_status/status'
SERVICES_LOG           = '/mnt/cephfs/lasair/services_log'
KAFKA_STREAMS          = '/mnt/cephfs/lasair/streams'
AREA_MOCS              = '/mnt/cephfs/lasair/areas'
WATCHLIST_MOCS         = '/mnt/cephfs/lasair/watchlists'
ANNOTATIONS_DUMP       = '/mnt/cephfs/lasair/annotations'
CROSSMATCH_TNS_DUMP    = '/mnt/cephfs/lasair/crossmatch_tns'
MYSQL_BACKUP_DIR       = '/mnt/cephfs/lasair/mysql_backup'

# Fast annotations
##################
# Fast annotations cause immediate kafka output
ANNOTATION_TOPIC       = 'ztf_annotations'
ANNOTATION_GROUP_ID    = 'test004'

# Webserver control
###################
# Can have different web look and feel for different clusters
WEB_DOMAIN             = '{{ lasair_name }}'

# To include links in emails of filter results
#LASAIR_URL             = 'lasair-iris.roe.ac.uk'
LASAIR_URL             = '{{ domain }}'

# The API calls this internal node for Sherlock
SHERLOCK_SERVICE       = "{{ groups['sherlock'][0] }}"

# The webserver calls on the API and should not be throttled
API_TOKEN              = '{{ settings.powerapi_token }}'

# Comparing what we have processed with what ZTF has processed
GRAFANA_USERNAME       = 'ztf'
GRAFANA_PASSWORD       = '{{ settings.grafana_password }}'

# Watchlist and Area control
############################
WATCHLIST_CHUNK        = 50000
WATCHLIST_MAX_DEPTH    = 13
AREA_MAX_DEPTH         = 13

# External brokers
###################
# Keeping the cache of the TNS database
TNS_URL                = 'https://www.wis-tns.org/system/files/tns_public_objects/'
TNS_API_KEY            = '{{ settings.tns_api_key }}'

# This one needs to be set BY HAND after the watchlist __TNS__  is created
TNS_WATCHLIST_ID       = 141  # hack hack

# Alerce streams
ALERCE_KAFKA           = '{{ settings.alerce_server }}'
ALERCE_PASSWORD        = '{{ settings.alerce_password }}'
ALERCE_GROUP_ID        = 'lasair003'

# Fink streams
FINK_USERNAME          = '{{ settings.fink_username }}'
FINK_GROUP_ID          = 'fink-roy'
FINK_TOPICS            = ['fink_early_sn_candidates_ztf']
FINK_SERVERS           = '{{ settings.fink_servers }}'
