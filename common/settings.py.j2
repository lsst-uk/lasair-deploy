# This settings file template controls the Lasair pipeline, webserver, cronjobs, 
# and command line operations.
# The template is instantiated on multiple nodes into settings.py
# and can then be modified locally.
# Note that github has this template file, but not the instantiations, 
# because those have secrets.

# Kafka operation
#################
# The internal address of the Kafka service by which pipeline components communicate
KAFKA_SERVER           = "{{ (groups['kafka'] | join(':9092,') ) }}:9092"

# Arbitrary Group ID for private Kafka, can be changed at will in an 
# instantiated settings.py
KAFKA_GROUPID          = 'LASAIR1'

# The server for the public kafka, where filter streams are prodced
# with its username and password
{% if groups['kafka_pub'] is defined and groups['kafka_pub']|length > 0 %}
PUBLIC_KAFKA_SERVER    = "{{ groups['kafka_pub'][0] }}:29092"
{% else %}
PUBLIC_KAFKA_SERVER    = None
{% endif %}
PUBLIC_KAFKA_USERNAME  = "{{ kafka_secret.admin_username }}"
PUBLIC_KAFKA_PASSWORD  = "{{ kafka_secret.admin_password }}"

# Internal address of the public kafka producer
INTERNAL_KAFKA_PRODUCER= "{{ (groups['kafka'] | join(':9092,') ) }}:9092"

# Group ID for public kafka, can be changed at will in an instantiated settings.py
PUBLIC_GROUP_ID        = 'test124'

# Pipeline runtime
##################
# If not present, pipeline comonents will not start a new batch
LOCKFILE               = '/home/ubuntu/lockfile'

# Alerts per batch. Can be modified in an instantiated settings.py
KAFKA_MAXALERTS        = 40000

# Time to wait between batches
WAIT_TIME              = 180

# When something goes wrong
SLACK_URL              = 'https://hooks.slack.com/services/{{ settings.slack_url_urlhook }}'

# Relational database mysql/galera
##################################
DB_HOST                = '{{ db_host }}'
DB_PORT                = '{{ db_port }}'
DB_DATABASE            = 'ztf'
DB_ROOT_PASS           = '{{ settings.master_db_root_password }}'
BACKUP_DATABASE_HOST   = "{{ (groups['db'] + groups['backend_db'] + [None])[0] }}"
BACKUP_DATABASE_PORT   = 3306

# Read/write access
DB_USER_READWRITE      = '{{ settings.master_db_username }}'
DB_PASS_READWRITE      = '{{ settings.master_db_password }}'

# Read only access
DB_USER_READONLY       = '{{ settings.master_db_readonly_username }}'
DB_PASS_READONLY       = '{{ settings.master_db_readonly_password }}'

# Local database on filter nodes
LOCAL_DB_HOST           = 'localhost'
LOCAL_DB_USER           = 'ztf'
LOCAL_DB_PASS           = '{{ settings.local_db_password }}'

# Cassandra NoSQL database
##########################
# Cassandra headnode
CASSANDRA_HEAD          = {{ groups['cassandranodes'] }}

# Table names
CASSANDRA_CANDIDATES    = 'candidates'
CASSANDRA_NONCANDIDATES = 'noncandidates'

# Directories on share Cephfs
#############################
IMAGEFITS              = '/mnt/cephfs/lasair/fits'
SYSTEM_STATUS          = '/mnt/cephfs/lasair/system_status/status'
SERVICES_LOG           = '/mnt/cephfs/lasair/services_log'
KAFKA_STREAMS          = '/mnt/cephfs/lasair/streams'
AREA_MOCS              = '/mnt/cephfs/lasair/areas'
WATCHLIST_MOCS         = '/mnt/cephfs/lasair/watchlists'
ANNOTATIONS_DUMP       = '/mnt/cephfs/lasair/annotations'
CROSSMATCH_TNS_DUMP    = '/mnt/cephfs/lasair/crossmatch_tns'
MYSQL_BACKUP_DIR       = '/mnt/cephfs/lasair/mysql_backup'

# Fast annotations
##################
# Fast annotations cause immediate kafka output
ANNOTATION_TOPIC       = 'ztf_annotations'
ANNOTATION_GROUP_ID    = 'test004'

# Webserver control
###################
# Can have different web look and feel for different clusters
WEB_DOMAIN             = '{{ lasair_name }}'

# To include links in emails of filter results
#LASAIR_URL             = 'lasair-iris.roe.ac.uk'
LASAIR_URL             = '{{ lasair_name }}.{{ domain }}'

# The API calls this internal node for Sherlock
{% if groups['sherlock'] is defined and groups['sherlock']|length > 0 %}
SHERLOCK_SERVICE       = "{{ groups['sherlock'][0] }}"
{% else %}
SHERLOCK_SERVICE       = None
{% endif %}

# The webserver calls on the API and should not be throttled
API_TOKEN              = '{{ settings.powerapi_token }}'

# Comparing what we have processed with what ZTF has processed
GRAFANA_USERNAME       = 'ztf'
GRAFANA_PASSWORD       = '{{ settings.grafana_password }}'
LASAIR_GRAFANA_URL     = "https://{{ lasair_name }}-svc.{{ domain }}/d/iILmd8-Wz/alerts"

# Watchlist and Area control
############################
WATCHLIST_CHUNK        = 50000
WATCHLIST_MAX_DEPTH    = 13
AREA_MAX_DEPTH         = 13
# default expiration in days for filter/watchlist/watchmap
ACTIVE_EXPIRE          = 180 

# External brokers
###################
# Keeping the cache of the TNS database
TNS_URL                = 'https://www.wis-tns.org/system/files/tns_public_objects/'
TNS_API_KEY            = '{{ settings.tns_api_key }}'

# This one needs to be set BY HAND after the watchlist __TNS__  is created
TNS_WATCHLIST_ID       = 1

# Alerce streams
ALERCE_KAFKA           = '{{ settings.alerce_server }}'
ALERCE_PASSWORD        = '{{ settings.alerce_password }}'
ALERCE_GROUP_ID        = 'lasair003'

# Fink streams
FINK_USERNAME          = '{{ settings.fink_username }}'
FINK_GROUP_ID          = 'fink-roy'
FINK_TOPICS            = [
    'fink_early_sn_candidates_ztf',
    'fink_sn_candidates_ztf',
    'fink_kn_candidates_ztf',
    'fink_early_kn_candidates_ztf',
    'fink_rate_based_kn_candidates_ztf',
]
FINK_SERVERS           = '{{ settings.fink_servers }}'
